# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IEjy8uIVEqFz1tm2-KXKedHk1IPxzDXa
"""

!pip install scikit-learn

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model

from google.colab import drive
import os
import cv2
import numpy as np

drive.mount('/content/drive')

!pip install tensorflow==2.15.0

data_dir = '/content/drive/My Drive/Dataset'

def preprocess_images(data_dir):
    images = []
    labels = []
    for label, person in enumerate(os.listdir(data_dir)):
        person_path = os.path.join(data_dir, person)
        for image_file in os.listdir(person_path):
            image_path = os.path.join(person_path, image_file)
            image = cv2.imread(image_path)
            image = cv2.resize(image, (224, 224))  # Resize to a consistent size
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
            image = np.stack((image,)*3, axis=-1)  # Replicate grayscale image across 3 channels
            image = image / 255.0  # Normalize pixel values to [0, 1]
            images.append(image)
            labels.append(label)
    return np.array(images), np.array(labels)

# Preprocess images
images, labels = preprocess_images(data_dir)

X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)



# Check the shape of the data
print("Shape of images:", images.shape)
print("Shape of labels:", labels.shape)

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Print the input shape of the model
print("Model input shape:", base_model.input_shape)

from tensorflow.keras.models import load_model

# Load MobileNetV2 model without top layer
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add custom layers for face recognition
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(10, activation='softmax')(x)  # Assuming num_classes is 10 for 10 individuals

# Combine base model and custom layers
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)
# Train the model


# Save the trained model
model.save('/content/drive/My Drive/saved_models/model.h5')

# Load the model
saved_model = load_model('/content/drive/My Drive/saved_models/model.h5')

# Evaluate the model on the test set (assuming you have a separate test set)
test_loss, test_accuracy = saved_model.evaluate(X_test, y_test)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)